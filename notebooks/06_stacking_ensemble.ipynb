{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155f236a",
   "metadata": {},
   "source": [
    "# Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb8545",
   "metadata": {},
   "source": [
    "## Setup and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ff5c8-20fe-42b9-a8c8-fea1ea396c82",
   "metadata": {},
   "source": [
    "### Imports + config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e32dad7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 — Stacking Ensemble\n",
      "Artifacts will be saved to: ..\\experiments\\ensemble\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ------------------------------\n",
    "# Global config\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "ENSEMBLE_DIR = Path(\"../experiments/ensemble\")\n",
    "ENSEMBLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def savefig(name):\n",
    "    plt.savefig(ENSEMBLE_DIR / name, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Day 7 — Stacking Ensemble\")\n",
    "print(\"Artifacts will be saved to:\", ENSEMBLE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1284e4-ee54-49ac-a018-ff4d44f1231f",
   "metadata": {},
   "source": [
    "### Load final processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74994801-507d-46f2-817a-a155204b0ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (227845, 72)\n",
      "Test shape: (56962, 72)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/processed/train.csv\")\n",
    "test  = pd.read_csv(\"../data/processed/test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c832dba1-536e-4768-909c-0aff8bdb6a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class', 'timestamp', 'hour', 'dayofweek', 'amount_log', 'amount_scaled', 'merchant_id', 'device_type', 'geo_bucket', 'account_id', 'account_age_days', 'merchant_freq', 'account_txn_count', 'device_freq', 'last_5_mean_amount', 'last_5_count', 'merchant_id_fe', 'device_type_fe', 'geo_bucket_fe', 'account_id_fe', 'amount_times_age', 'is_new_merchant', 'merchant_id_missing', 'device_type_missing', 'geo_bucket_missing', 'account_age_days_missing', 'pca_x', 'pca_y', 'anomaly_score', 'is_anomaly', 'cluster_id', 'mlp_proba', 'ae_latent_1', 'ae_latent_2', 'ae_latent_3', 'ae_latent_4', 'ae_latent_5', 'ae_latent_6', 'ae_latent_7', 'ae_latent_8', 'ae_recon_error', 'xgb_proba']\n"
     ]
    }
   ],
   "source": [
    "print(train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f0efd-235a-45d1-9317-83a2b33db073",
   "metadata": {},
   "source": [
    "everything looks good we have every colummn we fixed xgb_proba issue good to go now "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a92266e-f2bf-453b-bf13-2399bb130cac",
   "metadata": {},
   "source": [
    "## Define Meta-Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58530c0-986a-4550-ade0-f46c80f1d7db",
   "metadata": {},
   "source": [
    "### Explicitly define meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "449e6ede-3766-49e6-aa07-fc00cf611a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-features used for stacking:\n",
      " - xgb_proba\n",
      " - anomaly_score\n",
      " - ae_recon_error\n",
      " - mlp_proba\n",
      " - cluster_id\n",
      " - amount_log\n",
      " - merchant_freq\n",
      " - account_txn_count\n",
      " - last_5_mean_amount\n"
     ]
    }
   ],
   "source": [
    "META_FEATURES = [\n",
    "    \"xgb_proba\",\n",
    "    \"anomaly_score\",\n",
    "    \"ae_recon_error\",\n",
    "    \"mlp_proba\",\n",
    "    \"cluster_id\",\n",
    "    \"amount_log\",\n",
    "    \"merchant_freq\",\n",
    "    \"account_txn_count\",\n",
    "    \"last_5_mean_amount\",\n",
    "]\n",
    "\n",
    "print(\"Meta-features used for stacking:\")\n",
    "for f in META_FEATURES:\n",
    "    print(\" -\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28157b02-d462-47c7-bd26-797a8039c738",
   "metadata": {},
   "source": [
    "### Meta-Feature Selection for Stacking\n",
    "\n",
    "The stacking model does not consume raw transaction features. Instead, it operates on a curated set of high-level signals that summarize different perspectives on fraud risk.\n",
    "\n",
    "**Supervised probability signals**\n",
    "- `xgb_proba`: Primary fraud probability from a strong tree-based model trained on full engineered features.\n",
    "- `mlp_proba`: Secondary probability capturing nonlinear interactions learned by a neural network.\n",
    "\n",
    "**Unsupervised anomaly signals**\n",
    "- `anomaly_score`: IsolationForest score measuring deviation from population-level behavior.\n",
    "- `ae_recon_error`: Autoencoder reconstruction error capturing deep nonlinear abnormality.\n",
    "\n",
    "**Behavioral context features**\n",
    "- `cluster_id`: Coarse behavioral grouping from unsupervised clustering.\n",
    "- `amount_log`: Log-scaled transaction amount for stable magnitude comparison.\n",
    "- `merchant_freq`: Merchant occurrence frequency providing rarity context.\n",
    "- `account_txn_count`: Account activity level indicating behavioral maturity.\n",
    "- `last_5_mean_amount`: Short-term spending behavior for drift detection.\n",
    "\n",
    "Raw identifiers, visualization-only features, and thresholded anomaly flags are explicitly excluded to avoid leakage and instability. This feature set forms the final, frozen input contract for the ensemble model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb0084-6e06-4c01-b8b6-c7649b122fa0",
   "metadata": {},
   "source": [
    "### Build meta feature matix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15756d50-a563-497e-a892-4a63add69022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta feature matrices constructed.\n",
      "\n",
      "X_meta_train shape: (227845, 9)\n",
      "y_meta_train shape: (227845,)\n",
      "X_meta_test shape: (56962, 9)\n",
      "y_meta_test shape: (56962,)\n",
      "\n",
      "Meta feature columns:\n",
      " - xgb_proba\n",
      " - anomaly_score\n",
      " - ae_recon_error\n",
      " - mlp_proba\n",
      " - cluster_id\n",
      " - amount_log\n",
      " - merchant_freq\n",
      " - account_txn_count\n",
      " - last_5_mean_amount\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Targets\n",
    "y_meta_train = train[\"Class\"].astype(\"int32\")\n",
    "y_meta_test  = test[\"Class\"].astype(\"int32\") if \"Class\" in test.columns else None\n",
    "\n",
    "# Meta feature matrices\n",
    "X_meta_train = train[META_FEATURES].copy()\n",
    "X_meta_test  = test[META_FEATURES].copy()\n",
    "\n",
    "# Sanity checks\n",
    "assert list(X_meta_train.columns) == META_FEATURES, \"Train meta-feature order mismatch\"\n",
    "assert list(X_meta_test.columns) == META_FEATURES, \"Test meta-feature order mismatch\"\n",
    "assert X_meta_train.isnull().sum().sum() == 0, \"NaNs in X_meta_train\"\n",
    "assert X_meta_test.isnull().sum().sum() == 0, \"NaNs in X_meta_test\"\n",
    "\n",
    "print(\"Meta feature matrices constructed.\\n\")\n",
    "\n",
    "print(\"X_meta_train shape:\", X_meta_train.shape)\n",
    "print(\"y_meta_train shape:\", y_meta_train.shape)\n",
    "\n",
    "print(\"X_meta_test shape:\", X_meta_test.shape)\n",
    "if y_meta_test is not None:\n",
    "    print(\"y_meta_test shape:\", y_meta_test.shape)\n",
    "\n",
    "print(\"\\nMeta feature columns:\")\n",
    "for col in X_meta_train.columns:\n",
    "    print(\" -\", col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba423939-efab-496b-9957-9d8a292c7fd6",
   "metadata": {},
   "source": [
    "## Cross-Validated Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37d07a-ff71-4b7e-a3f6-0f61f08dac18",
   "metadata": {},
   "source": [
    "### CV setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64f1e04e-ce13-4842-bad0-72a27d2c19a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold configured:\n",
      " - n_splits: 5\n",
      " - shuffle: True\n",
      " - random_state: 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"StratifiedKFold configured:\")\n",
    "print(\" - n_splits:\", skf.n_splits)\n",
    "print(\" - shuffle:\", skf.shuffle)\n",
    "print(\" - random_state:\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb3fd3-3c36-418b-93b8-56a2b5d80fc0",
   "metadata": {},
   "source": [
    "“We evaluate the stacking model using stratified cross-validation before training on the full dataset to ensure that performance gains are real and not artifacts of overfitting.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32f674-f53c-4e65-abe6-64f73f940b89",
   "metadata": {},
   "source": [
    "### Cross-validated evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10fcf667-dc65-4a9f-8629-ea7c82d0f7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "{'fold': 1, 'pr_auc': 1.0, 'roc_auc': 1.0, 'recall@0.5': 1.0, 'f1@0.5': 1.0}\n",
      "\n",
      "Fold 2\n",
      "{'fold': 2, 'pr_auc': 1.0000000000000002, 'roc_auc': 1.0, 'recall@0.5': 1.0, 'f1@0.5': 1.0}\n",
      "\n",
      "Fold 3\n",
      "{'fold': 3, 'pr_auc': 1.0000000000000002, 'roc_auc': 1.0, 'recall@0.5': 1.0, 'f1@0.5': 1.0}\n",
      "\n",
      "Fold 4\n",
      "{'fold': 4, 'pr_auc': 1.0000000000000002, 'roc_auc': 1.0, 'recall@0.5': 1.0, 'f1@0.5': 1.0}\n",
      "\n",
      "Fold 5\n",
      "{'fold': 5, 'pr_auc': 0.9988484747438061, 'roc_auc': 0.9999980521522326, 'recall@0.5': 1.0, 'f1@0.5': 0.9937106918238994}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_meta_train, y_meta_train), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "\n",
    "    X_tr = X_meta_train.iloc[train_idx]\n",
    "    y_tr = y_meta_train.iloc[train_idx]\n",
    "\n",
    "    X_val = X_meta_train.iloc[val_idx]\n",
    "    y_val = y_meta_train.iloc[val_idx]\n",
    "\n",
    "    stacker = LogisticRegression(\n",
    "        class_weight=\"balanced\",\n",
    "        penalty=\"l2\",\n",
    "        solver=\"liblinear\",\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    stacker.fit(X_tr, y_tr)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_val_proba = stacker.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    pr_auc = average_precision_score(y_val, y_val_proba)\n",
    "    roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "    # Temporary threshold for inspection only\n",
    "    y_val_pred = (y_val_proba >= 0.5).astype(int)\n",
    "\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    fold_metrics = {\n",
    "        \"fold\": fold,\n",
    "        \"pr_auc\": pr_auc,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"recall@0.5\": recall,\n",
    "        \"f1@0.5\": f1\n",
    "    }\n",
    "\n",
    "    cv_results.append(fold_metrics)\n",
    "\n",
    "    print(fold_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eafceae-dfd8-4069-a2da-292000000787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fold': 1, 'pr_auc': 1.0, 'roc_auc': 1.0, 'recall@0.5': 1.0, 'f1@0.5': 1.0},\n",
       " {'fold': 2,\n",
       "  'pr_auc': 1.0000000000000002,\n",
       "  'roc_auc': 1.0,\n",
       "  'recall@0.5': 1.0,\n",
       "  'f1@0.5': 1.0},\n",
       " {'fold': 3,\n",
       "  'pr_auc': 1.0000000000000002,\n",
       "  'roc_auc': 1.0,\n",
       "  'recall@0.5': 1.0,\n",
       "  'f1@0.5': 1.0},\n",
       " {'fold': 4,\n",
       "  'pr_auc': 1.0000000000000002,\n",
       "  'roc_auc': 1.0,\n",
       "  'recall@0.5': 1.0,\n",
       "  'f1@0.5': 1.0},\n",
       " {'fold': 5,\n",
       "  'pr_auc': 0.9988484747438061,\n",
       "  'roc_auc': 0.9999980521522326,\n",
       "  'recall@0.5': 1.0,\n",
       "  'f1@0.5': 0.9937106918238994}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b20040-1901-492f-a059-2ee54220c604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd4f47-fbe9-498a-aeb9-ebb34d3299c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c952867-c53d-4bd6-86a3-50036121ca82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc410128-36c0-4c65-be6a-e5676a0aaad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
