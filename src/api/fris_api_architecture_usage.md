# ğŸš¨ FRIS API â€” Fraud Risk Intelligence System

This document explains **everything built in the API layer** of FRIS.
Not theory. Not hype. Actual engineering decisions, structure, and behavior.

If you read this endâ€‘toâ€‘end, you should understand **how a real ML model is served in production**.

---

## ğŸ¯ What This API Does

FRIS exposes a **productionâ€‘grade ML inference + explainability service** over HTTP.

It allows you to:

- ğŸ§  Send a **raw transaction** (no engineered features)
- âš¡ Get a **fraud risk score + label**
- ğŸ” Get **SHAPâ€‘based explanations** aligned with the prediction

All of this happens:
- deterministically
- using frozen feature contracts
- with identical training vs inference behavior

---

## ğŸ§± Highâ€‘Level Architecture

```
Client (Swagger / Script / Frontend)
        â†“ JSON
FastAPI (API layer)
        â†“
Feature Inference (frozen pipeline)
        â†“
Models (XGB + Stack)
        â†“
Prediction / SHAP
        â†“
HTTP JSON Response
```

Key principle:
> **The API does NOT do ML. It only wires requests to alreadyâ€‘verified logic.**

---

## ğŸ“ API Folder Structure

```
src/api/
â”œâ”€â”€ main.py        # FastAPI app + lifecycle + routes
â”œâ”€â”€ schemas.py     # Input contracts (Pydantic)
â”œâ”€â”€ test_client.py # Endâ€‘toâ€‘end API tests
â””â”€â”€ __init__.py
```

Each file has a single responsibility. No overlap. No magic.

---

## ğŸš€ `main.py` â€” The API Entry Point

### Responsibilities

- Create the FastAPI app
- Load ML artifacts **once at startup**
- Expose HTTP endpoints
- Never contain ML logic

### Lifespan (Startup Logic)

We use FastAPI **lifespan** instead of deprecated startup hooks:

- Models are loaded once
- SHAP explainer is built once
- Objects live for the entire app lifetime

This guarantees:
- âš¡ No reload per request
- ğŸ§  Consistent inference
- ğŸ§ª Tests behave like production

---

## ğŸ”Œ Global Objects (Why They Exist)

```python
MODELS = None
EXPLAINER = None
```

These are:
- readâ€‘only
- initialized at startup
- reused across requests

This is **standard practice in ML serving**.

---

## ğŸ›£ï¸ API Endpoints

### ğŸ©º `GET /health`

Purpose:
- Check service liveness
- Used by load balancers, Docker, Kubernetes

Response:
```json
{ "status": "ok" }
```

---

### âš¡ `POST /predict`

Purpose:
- Run fraud inference

Input:
- Raw transaction JSON
- Validated by schema

Output:
```json
{
  "score": 0.0,
  "label": "legit"
}
```

Rules:
- No feature engineering here
- No SHAP here
- Fast and deterministic

---

### ğŸ” `POST /explain`

Purpose:
- Explain **exactly the same prediction**

Output:
```json
[
  { "feature": "V3", "value": 2.53, "shap_value": -0.86 },
  ...
]
```

Rules:
- Uses same feature row as prediction
- No recomputation
- No guessing columns

---

## ğŸ“œ `schemas.py` â€” API Contracts

Schemas define **what the API accepts**, not what the model uses internally.

### `TransactionInput`

- Matches raw dataset exactly
- Includes:
  - `Time`
  - `V1` â€¦ `V28`
  - `Amount`
- âŒ No engineered features
- âŒ No `Class`

Benefits:
- ğŸ§± Strong boundary validation
- ğŸ“– Autoâ€‘generated docs
- ğŸ§  No garbage reaches the model

---

## ğŸ§ª `test_client.py` â€” Why This Exists

These are **true endâ€‘toâ€‘end tests**.

They verify:
- API starts correctly
- Lifespan runs
- Models load
- `/health` works
- `/predict` returns valid structure
- `/explain` returns SHAP output

Important detail:

```python
with TestClient(app) as client:
```

This ensures:
- startup lifecycle is executed
- tests mirror real production behavior

Without this, tests lie.

---

## ğŸ§  Key Engineering Lessons

### âœ… Contracts First

- Feature columns frozen
- Schema enforced
- No silent mismatches

### âœ… Training = Inference

- Same pipeline
- Same columns
- Same order

### âœ… Boring is Good

- No refactors
- No clever async
- No hidden state

### âœ… Loud Failures > Silent Bugs

- Validation errors are good
- Startup crashes are good
- Early failure prevents production disasters

---

## ğŸ§‘â€ğŸ’» How to Run Locally

```bash
uvicorn src.api.main:app --reload
```

Open:
- ğŸ“– Docs: http://127.0.0.1:8000/docs
- ğŸ©º Health: http://127.0.0.1:8000/health

---

## ğŸ§ª How to Test

```bash
pytest src/api/test_client.py
```

All tests must pass before:
- Docker
- Deployment
- Refactors

---

## ğŸš« Things We Explicitly Avoided

- Reâ€‘engineering features
- Wrapping models in magic classes
- Combining predict + explain prematurely
- Async complexity
- Hidden state mutation

These mistakes break ML systems quietly.

---

## ğŸ Final State

At this point, FRIS has:

- âœ… Productionâ€‘grade ML API
- âœ… Deterministic inference
- âœ… Explainability
- âœ… Schemaâ€‘validated inputs
- âœ… Lifecycleâ€‘safe startup
- âœ… Endâ€‘toâ€‘end tests

This API can now be:
- Dockerized
- Deployed
- Used by any client

---

ğŸ”¥ **This is not a tutorial API. This is how real ML systems are shipped.**

